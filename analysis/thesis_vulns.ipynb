{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c188ec4-a079-48d1-9dbf-829ed344c161",
   "metadata": {},
   "source": [
    "# Results for Q2 vulns in the thesis\n",
    "\n",
    "- (Potentially) vulnerable endpoints\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a4d14f-ac13-4acf-a7cd-f4da7792b9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879b2a3c-e9fa-47dd-a6a6-18674d0e2ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from requests.exceptions import SSLError, ConnectTimeout, ConnectionError\n",
    "from publicsuffix2 import PublicSuffixList\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helper_dyn import (get_pipeline_overview, get_cookie_stats, get_pipeline_stats, show_only_first, get_leak_data, display_timing,\n",
    "                        process_responses, display_response_summary, display_changed,\n",
    "                        parse_method_url, get_query, info_grouping, row_sym, get_conf_dfs,\n",
    "                        get_info_frames, get_only_both, parse_apg_url, url_list_to_tuples,\n",
    "                        get_predictions_retroactive, save_div, get_basic_pruning_reduction, \n",
    "                        get_combs_after_basic_pruning, get_stats, get_acc, calc_info_frames)\n",
    "from dil_preprocess import get_url_data, basic_pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8de4e2-904f-4e70-b5c9-27f81ab20d9a",
   "metadata": {},
   "source": [
    "# (Potentially) Vulnerable endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d664f2-c1e9-47ac-a61b-a2537d38f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_results = get_pipeline_overview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81da35ec-7c7f-4472-868e-87ee1fc761cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display general stats on the pipeline\n",
    "\n",
    "dat, conf_both, conf_any = get_pipeline_stats(site_results.loc[(~site_results[\"site\"].str.contains(r\"-unpruned|172\\.17\\.0.1:44320\")) & (site_results[\"tranco_rank\"] > 0)])\n",
    "\n",
    "\n",
    "# For a couple of websites, we needed to retest them, but the retest did not work. Exclude them from the rest of the analysis\n",
    "print(\"Remove ones that did not login correctly\\n\\n\")\n",
    "# Problem: 3 of the first URLs tested are reported to be vulnerable here (without a confirmed_df_dict)\n",
    "# However, they are not vulnerable (in chrome) according to our newer definiton of \"same\"\n",
    "dat, conf_both, conf_any = get_pipeline_stats(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a2b5e-d45b-48b6-8e81-6f1f887fc092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display info on how many URLs were tested, retestend and confirmed\n",
    "# Grouped by site, browser and method (and combinations thereof)\n",
    "for col in [\"dyn_conf_urls\", \"dyn_conf_retest_urls\", \"confirmed_leak_urls\"]:\n",
    "    print(col)\n",
    "    acc = []\n",
    "    dat.apply(parse_method_url, col=col, acc=acc, axis=1)\n",
    "    dyn_conf = pd.DataFrame(acc)\n",
    "\n",
    "    with pd.option_context('display.max_rows', 20):\n",
    "        for grouping in [[\"site\"], [\"site\", \"browser\"], [\"method\"], [\"browser\", \"method\"], [\"site\", \"browser\", \"method\"]]:\n",
    "            print(grouping)\n",
    "            dyn_browser = dyn_conf.groupby(grouping)[[\"url\"]].count()\n",
    "            display(dyn_browser.agg([\"min\", \"max\", \"mean\"]))\n",
    "            display(dyn_browser.sort_values(\"url\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf943750-f6a4-4799-b3d2-11324c9dfde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all dfs of the confirmed XS-Leaks into one dataframe\n",
    "df_all = get_conf_dfs(conf_any) #dat.loc[dat[\"crawl_end\"] != \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c108e8-2882-4c21-8e02-9edc5419b50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information on the confirmed vulns\n",
    "display(df_all.agg([\"nunique\", \"unique\", \"count\"]))\n",
    "display(df_all.groupby([\"site\", \"browser\"]).agg([\"nunique\", \"unique\", \"count\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f4154d-db50-4042-9a1d-2a528878cacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show which sites are responsible for most results\n",
    "df_all_summ = df_all[df_all.columns.difference([\"value_cookies\", \"value_no_cookies\"])].groupby(\"site\").nunique().sort_values(\"url\", ascending=False)\n",
    "display(df_all_summ.agg([\"count\", \"mean\", \"max\", \"sum\"]))\n",
    "with pd.option_context(\"max_rows\", 50):\n",
    "    display(df_all_summ[[\"apg_url\", \"url\", \"browser\", \"inc_method\", \"method\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebabbd6-9644-4dd2-bf0b-2f0f15f1924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all leak URL (apg URL) data\n",
    "# We can now only look at the leak URLs tested in both browsers, \n",
    "# or only at the ones tested in only one browser\n",
    "sites = dat[\"site\"].tolist()\n",
    "leak_urls = url_list_to_tuples(dat[\"dyn_conf_urls\"].tolist(), sites)\n",
    "leak_url_set = set(list(leak_urls.itertuples(name=None, index=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e12dcab-265e-414a-b28d-de24edbbc717",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"max_rows\", 1000):\n",
    "    display(leak_urls.groupby([\"browser\"])[\"method\"].value_counts().to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830a8de7-7741-4985-8f9a-5b6bc379c544",
   "metadata": {},
   "source": [
    "### Methods that do not occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a26496b-08a5-4e56-9448-8c01afc933f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All inclusion methods/leak methods\n",
    "# On how many URLs/sites do they work? For chrome, firefox, and both!\n",
    "\n",
    "# Only 18 leak methods are tested in dil_postprocess#L433, get_working_channel\n",
    "# The others are excluded as they are either identical or should not work?!\n",
    "# The three tested ones that do not work are duration, videoHeight and videoWidth\n",
    "info_frame_0, _ = get_info_frames(df_all, None, conv_method=True)\n",
    "\n",
    "with pd.option_context(\"max_rows\", None):\n",
    "    display(info_frame_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e68bb2-ba59-4c36-9b64-58c839a2bd61",
   "metadata": {},
   "source": [
    "## Summary/Info frames for several settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c124a300-f04a-4042-8331-1aaf183e172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_frame = pd.read_pickle(\"data/header_frame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f99ab7-3361-4233-9ab6-52fce53f4e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the info frames\n",
    "\n",
    "# BGA dominates thesshhhhhhhhhhhhhhhhhhhhhSSSSSSS stats for many types (not leakable in chrome as sameSite=None without secure)\n",
    "# Remove it to see, what remains\n",
    "# df_all = df_all.loc[df_all[\"site\"] != \"boardgamearena.com\"]\n",
    "\n",
    "# Complete frame\n",
    "info_frame, info_frame_new = get_info_frames(df_all, None)\n",
    "# Prune all leak URLs only tested in one browser\n",
    "info_frame_both, info_frame_new_both = get_info_frames(df_all, leak_url_set, leave=[2])\n",
    "# Prune all leak URLs tested in both browsers\n",
    "info_frame_only, info_frame_new_only = get_info_frames(df_all, leak_url_set, leave=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5055454e-0d71-40a1-a090-a6ceb5d381dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"max_rows\", 1000):\n",
    "    display(info_frame_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9133815b-7690-46a5-8ca5-11c58f7200e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP-security-policy violations called for frame-ancestors of the embedded document\n",
    "# For XFO this leak channel does not exist, so one could distinguish whether a frame is blocked because of XFO or frame-ancestors\n",
    "df_all.loc[(df_all[\"method\"] == \"gp_securitypolicyviolation\") & ~(df_all[\"inc_method\"] == \"iframe-csp\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7ea1c-f904-48a5-aedb-88e770300fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[(df_all[\"method\"] == \"op_el_naturalHeight\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b120bf0-c419-475a-9c93-528a4f171257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iframe, object, embed, embed-img\n",
    "# (Firefox can (could, does not work anymore?) code 3XX and code 200 for most of these inclusion methods as it will fire load either once or twice)\n",
    "# The actual reason for most of this cases is: csp frame-ancestors!, some might have other reasons though (e.g., bga does not set frame-ancestors?)\n",
    "# Other reasons could be timeouts or invalid locations leading to infinite reload\n",
    "\n",
    "# Firefox can distingush 4XX and XFO from other codes or no XFO for object, embed and embed-img\n",
    "# Chrome can (only) distingush XFO on the object tag (bug?)\n",
    "\n",
    "# Chrome can distinguish valid images from no valid images on embed-img as it is treated the same as img\n",
    "\n",
    "# Chrome can count client-side redirects (refresh header, meta-refresh tag, javascript) on iframe, embed, and object\n",
    "# Firefox can do it aswell but needs higher wait_time timeouts\n",
    "\n",
    "iframe_event_list = df_all.loc[(df_all[\"method\"] == \"event_list\") & (df_all[\"inc_method\"] == \"object\")] # & (df_all[\"browser\"] == \"firefox\")]\n",
    "display(iframe_event_list)\n",
    "print(iframe_event_list[\"url\"].head(5).to_list())\n",
    "responses = header_frame.loc[header_frame[\"url\"].isin(iframe_event_list[\"url\"])]\n",
    "with pd.option_context(\"max_rows\", 101):\n",
    "    display(responses[[\"cookies\", \"site\", \"code\", \"content-type\", \"x-frame-options\", \"content-disposition\", \"cross-origin-resource-policy\", \"x-content-type-options\", \"cross-origin-opener-policy\"]].value_counts().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03040eaa-16df-4bff-97f5-2f7a30e4da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame count on window.open!\n",
    "# Chrome not possible if \n",
    "\n",
    "win_frame = df_all.loc[(df_all[\"method\"] == \"op_frame_count\") & (df_all[\"inc_method\"] == \"window.open\")]# & (df_all[\"browser\"] == \"chrome\")]\n",
    "win_frame = win_frame.loc[(win_frame[\"value_cookies\"] == \"Not possible\") | (win_frame[\"value_no_cookies\"] == \"Not possible\")]\n",
    "print(len(win_frame))\n",
    "display(win_frame)\n",
    "#win_frame[\"value_cookies\"] = win_frame[\"value_cookies\"].apply(tuple)\n",
    "#win_frame[\"value_no_cookies\"] = win_frame[\"value_no_cookies\"].apply(tuple)\n",
    "print(win_frame[\"url\"].head(5).to_list())\n",
    "responses = header_frame.loc[header_frame[\"url\"].isin(win_frame[\"url\"])]\n",
    "with pd.option_context(\"max_rows\", 200):\n",
    "    #display(win_frame.pivot_table(index=[\"value_cookies\", \"value_no_cookies\"], aggfunc=\"count\"))\n",
    "\n",
    "    display(responses[[\"cookies\", \"site\", \"code\", \"content-type\", \"x-frame-options\", \"content-disposition\", \"cross-origin-resource-policy\", \"x-content-type-options\", \"cross-origin-opener-policy\"]].value_counts().to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a960dda5-8c1e-471d-b437-deabff44ecc3",
   "metadata": {},
   "source": [
    "## Main vuln tables including export to latex!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76351c3-8036-43bf-92f3-e697fb3f0cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info_frame_new[\"type\"].value_counts())\n",
    "vuln_overview = info_frame_new.loc[info_frame_new[\"type\"].isin([\"browsers\", \"inc_methods\", \"leak_methods\"])].filter(regex=\"^(?!.*base)\", axis=1).filter(regex=\"^(?!.*leak)\", axis=1).filter(regex=\"^(?!.*channel)\", axis=1)\n",
    "vuln_channels = info_frame_new.loc[info_frame_new[\"type\"].isin([\"leak_channels\"])].filter(regex=\"^(?!.*base)\", axis=1).filter(regex=\"^(?!.*leak)\", axis=1).filter(regex=\"^(?!.*channel)\", axis=1)\n",
    "vuln_sites = info_frame_new.loc[info_frame_new[\"type\"].isin([\"sites\"])].filter(regex=\"^(?!.*base)\", axis=1).filter(regex=\"^(?!.*leak)\", axis=1).filter(regex=\"^(?!.*channel)\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bc040b-72d8-49ec-96c3-c8b22d947734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for vuln in [vuln_overview, vuln_channels, vuln_sites]:\n",
    "for title, vuln in [(\"vuln_overview\", vuln_overview), (\"vuln_sites\", vuln_sites), (\"vuln_channels\", vuln_channels)]:\n",
    "    with pd.option_context(\"max_rows\", 50):\n",
    "        vuln = vuln.apply(pd.to_numeric, errors=\"ignore\")\n",
    "        #display(vuln)\n",
    "        #display(vuln.describe().round(2))\n",
    "        vuln = vuln.replace(r\"_\", \"-\", regex=True)\n",
    "        vuln[\"subtype\"] = vuln[\"subtype\"].apply(str).replace(r\"_\", \"-\", regex=True)\n",
    "        if title == \"vuln_channels\":\n",
    "            vuln = vuln.loc[~(vuln[\"subtype\"].str.contains(\"load-count\")) & ~(vuln[\"subtype\"].str.contains(\"event-set\"))]\n",
    "        vuln = vuln.loc[:, vuln.columns != \"type\"]\n",
    "        vuln = vuln.rename(columns={\"subtype\": \"Group\"})\n",
    "        vuln = vuln.replace({\"browsers\": \"all\"})\n",
    "        vuln.columns = vuln.columns.str.replace(r'confirmed ', '')\n",
    "        vuln.columns = vuln.columns.str.replace(r'sites', 'Sites')\n",
    "        vuln.columns = vuln.columns.str.replace(r'firefox', 'Firefox')\n",
    "        vuln.columns = vuln.columns.str.replace(r'chrome', 'Chrome')\n",
    "        vuln = vuln.loc[~(vuln[\"Group\"].str.contains(\"event-set\"))]\n",
    "        vuln = vuln.loc[~(vuln[\"Group\"].str.contains(\"load-count\"))]\n",
    "        vuln = vuln.loc[~(vuln[\"Group\"].str.contains(\"CSS2\"))]\n",
    "        vuln = vuln.loc[~(vuln[\"Group\"].str.contains(\"op-win-window\"))]\n",
    "        vuln = vuln.loc[~(vuln[\"Group\"].str.contains(\"naturalHeight\"))]\n",
    "\n",
    "        vuln = vuln.loc[:, vuln.columns != \"Sites any browser\"]\n",
    "\n",
    "\n",
    "\n",
    "        with open(f\"tables/{title}.tex\", \"w\") as f:\n",
    "            display(vuln)\n",
    "            f.write(vuln.to_latex(index=False, escape=False ,header=['\\\\rotatebox{90}{' + c + '}' for c in vuln.columns]))\n",
    "        desc = vuln.filter(regex=\"^(?!.*Sites)\", axis=1).describe().round(2)\n",
    "        desc.index = desc.index.str.replace(r\"%\", \"\\%\", regex=True)\n",
    "        desc = desc.loc[desc.index.isin([\"mean\", \"std\", \"min\", \"50\\%\", \"max\"])]\n",
    "        with open(f\"tables/{title}_sum.tex\", \"w\") as f:\n",
    "            display(desc)\n",
    "            #f.write(desc.to_latex(escape=False ,header=['\\\\rotatebox{90}{' + c + '}' for c in desc.columns]))\n",
    "            f.write(desc.to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de49a0d-c685-431f-acab-02447b6781c4",
   "metadata": {},
   "source": [
    "### Additional investigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4717e0a0-226c-46e6-b594-b6882fd23785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get responses where gp-window-onerror works!\n",
    "onerror = df_all.loc[df_all[\"method\"] == \"gp_window_onerror\"]\n",
    "# onerror = onerror.loc[onerror[\"browser\"] == \"chrome\"]\n",
    "onerror_responses = header_frame.loc[header_frame[\"url\"].isin(onerror[\"url\"])]\n",
    "# If statuscode is 400 or 401, no error will be thrown\n",
    "# If nosniff is set (on html) no error will be thrown\n",
    "# In chrome if the body is html (and some other), no error will be thrown due to CORB\n",
    "# Chrome defaults to Lax\n",
    "# The boardgame arena thing is strange?\n",
    "# It now throws errors for both states (responses are still the same; sometimes the onerror handler seems to fail, but then not only one state should have observed errors and the other no errors, but a mix?)\n",
    "# Investigate in the old firefox version used?! or retest bga?, maybe FP (e.g., because the requests timed out?)\n",
    "# (Possible reason, it had nosniff like pandadoc.com?, but unlikely)\n",
    "with pd.option_context(\"max_rows\", 101):\n",
    "    display(onerror_responses[[\"cookies\", \"site\", \"code\", \"content-type\", \"x-frame-options\", \"content-disposition\", \"cross-origin-resource-policy\", \"x-content-type-options\", \"cross-origin-opener-policy\"]].value_counts().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129e2d77-e91a-40a3-94bb-60afb9e01659",
   "metadata": {},
   "outputs": [],
   "source": [
    "onerror.loc[onerror[\"site\"] == \"boardgamearena.com\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a275ae7d-ae68-419d-8fcd-b2a0b1ac5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[(df_all[\"inc_method\"] == \"iframe\") & (df_all[\"method\"] == \"event_list\")].groupby(\"site\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d806418e-0b37-4144-b429-43ae03ec9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[(df_all[\"inc_method\"] == \"iframe-csp\") & (df_all[\"method\"] == \"op_win_origin\")].groupby(\"site\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b47dbc-2d17-4fad-a57d-6f633ef341fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[(df_all[\"inc_method\"] == \"link-prefetch\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8246486-5c60-481e-8d47-abc067aa1cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get responses where link-stylesheet works!\n",
    "style = df_all.loc[df_all[\"inc_method\"] == \"link-stylesheet\"]\n",
    "style_responses = header_frame.loc[header_frame[\"url\"].isin(style[\"url\"])]\n",
    "\n",
    "# Chrome accepts almost all content-types, so it can be used to distinguish code only\n",
    "# Firefox only accepts text/css (and empty)\n",
    "with pd.option_context(\"max_rows\", 101):\n",
    "    display(style_responses[[\"cookies\", \"code\", \"content-type\", \"x-frame-options\", \"content-disposition\", \"cross-origin-resource-policy\", \"x-content-type-options\", \"cross-origin-opener-policy\"]].value_counts().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55357bf5-2712-4c73-8819-e04c3b4cc8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get responses where op_win_CSS2Properties works for iframe\n",
    "iframe_win = df_all.loc[(df_all[\"inc_method\"] == \"iframe-csp\") & (df_all[\"method\"] == \"op_win_CSS2Properties\")]\n",
    "iframe_responses = header_frame.loc[header_frame[\"url\"].isin(iframe_win[\"url\"])]\n",
    "\n",
    "# If a frame is blocked due to CSP, firefox can directly access the frame as it falls back to an empty frame of the origin of the current page\n",
    "# In chrome one cannot access the frame as it is a special \"blocked\" frame with the original origin\n",
    "\n",
    "# einpresswire.com probably has the wrong data in the crawl data (either in the dyn confirmation only one redirected, or one redirect did not cause a CSP block)\n",
    "with pd.option_context(\"max_rows\", 101):\n",
    "    display(iframe_responses[[\"cookies\", \"site\", \"code\", \"content-type\", \"x-frame-options\", \"content-disposition\", \"cross-origin-resource-policy\", \"x-content-type-options\", \"cross-origin-opener-policy\"]].value_counts().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cb70f3-a63a-40ec-a669-545f74f1d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"max_rows\", 10):\n",
    "    display(iframe_win)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06bd542-914c-4b98-8e2f-fd6fc714de97",
   "metadata": {},
   "source": [
    "## Explain differences chrome/firefox\n",
    "\n",
    "- Remove explained by sameSite\n",
    "    - estimate one: 60\n",
    "    - estimate two: 54\n",
    "    - (estimate three: 121)\n",
    "- Remove explained by tree pruning (corb, different parsing and co)\n",
    "    - info_frame_only and both\n",
    "    - in addition and without removing sameSite\n",
    "- Remove all URLs also found by another inc channel/leak method, i.e, only have URLs remaining that were only found by this one inc channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662ea2e-3b4d-468e-aa1f-ef76674d0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all sites that have >1 non window.open case in firefox and 0 non window.open case in chrome\n",
    "# From the table with only URLs tested by both\n",
    "# These should be sites with sameSite rules preventing chrome from being leaky (not 100%, but almost?)\n",
    "# Remove them from the above table, to investigate other cases that are harder to explain\n",
    "inf = info_frame_new.loc[(info_frame_new[\"type\"] == \"inc_sites\") & (~info_frame_new[\"subtype\"].apply(str).str.contains(\"window.open\"))][[\"subtype\", \"confirmed URLs firefox\", \"confirmed URLs chrome\"]]\n",
    "inf[\"site\"], inf[\"inc_method\"] = zip(*inf[\"subtype\"])\n",
    "inf[\"confirmed URLs firefox\"] = inf[\"confirmed URLs firefox\"].apply(int)\n",
    "inf[\"confirmed URLs chrome\"] = inf[\"confirmed URLs chrome\"].apply(int)\n",
    "\n",
    "inf_piv = inf.pivot_table(index=\"site\", values=[\"confirmed URLs firefox\", \"confirmed URLs chrome\"], aggfunc=\"sum\")\n",
    "display(inf_piv)\n",
    "# Estimate 1\n",
    "samesite_chrome_sites = inf_piv.loc[(inf_piv[\"confirmed URLs chrome\"] <= 0) & (inf_piv[\"confirmed URLs firefox\"] >= 1)].reset_index()[\"site\"].tolist()\n",
    "# Estimate 2\n",
    "# samesite_chrome_sites = inf_piv.loc[(inf_piv[\"confirmed URLs chrome\"] <= 1) & (inf_piv[\"confirmed URLs firefox\"] >= 2)].reset_index()[\"site\"].tolist()\n",
    "\n",
    "print(f\"{len(samesite_chrome_sites)} sites do not leak for any URL requiring sameSite=None,secure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa093cb-2e26-42d6-916b-09f566c29663",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = site_results.loc[(~site_results[\"site\"].str.contains(r\"-unpruned|172\\.17\\.0.1:44320\")) & (site_results[\"tranco_rank\"] > 0)]\n",
    "cookie_hunter_second_failed = ['allevents.in', 'whowhatwear.com', 'creative-tim.com', 'extendoffice.com', 'lepoint.fr', 'hallmark.com', 'flourish.studio', 'dramacool.fm', 'pdfdrive.com', 'jmty.jp', 'readymag.com', 'gridoto.com', 'grubhub.com', 'asana.com', 'familyeducation.com', 'entireweb.com', 'christianpost.com', 'cutt.us', 'tiexue.net', 'lejdd.fr', 'brisbanetimes.com.au']\n",
    "filtered = filtered.loc[~filtered[\"site\"].isin(cookie_hunter_second_failed)]\n",
    "\n",
    "# Addititional filters\n",
    "# Remove all URLs that work in more than one inclusion method\n",
    "(_, inf_new_rem), (_, inf_new_both_rem), (_, inf_new_only_rem) = calc_info_frames(filtered, remove_multiple=\"method\")  # Only look at URLs that only worked for a single inc_method (or method), ...\n",
    "# (_, inf_new_rem), (_, inf_new_both_rem), (_, inf_new_only_rem) = calc_info_frames(filtered, remove_multiple=\"inc_method\")  # Only look at URLs that only worked for a single inc_method (or method), ...\n",
    "\n",
    "\n",
    "# Remove sameSite non working, ...\n",
    "filtered = filtered.loc[(~filtered[\"site\"].isin(samesite_chrome_sites))]\n",
    "(_, inf_new), (_, inf_new_both), (_, inf_new_only) = calc_info_frames(filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03259c-f99f-41cb-9eee-5f9462065314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leak URLs not tested\n",
    "with pd.option_context(\"max_rows\", None):\n",
    "    with pd.option_context(\"max_columns\", 25):\n",
    "        for typ in [\"browsers\", \"inc_methods\", \"leak_methods\", \"leak_channels\", \"inc_sites\"]:\n",
    "        # When all incs except window.open do not work for chrome, this site can be explained by sameSite\n",
    "        #for typ in [\"browsers\", \"inc_sites\"]:\n",
    "            for df, info in [(info_frame_new, \"all\"), (info_frame_new_only, \"leak URLs not tested in other browser\"), (info_frame_new_both, \"leak URLs tested in other browser\")]:\n",
    "                print(info)\n",
    "                display(df.loc[df[\"type\"] == typ].filter(regex=\"^(?!.*base)\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b72274-8b64-4f43-9bd0-9f368c704880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leak URLs not tested + remove sameSite estimated pages\n",
    "with pd.option_context(\"max_rows\", None):\n",
    "    with pd.option_context(\"max_columns\", 25):\n",
    "        #for typ in [\"browsers\", \"inc_methods\", \"leak_methods\", \"leak_channels\", \"inc_sites\"]:\n",
    "        for typ in [\"browsers\", \"inc_methods\", \"leak_channels\"]:\n",
    "            for df, info in [(inf_new, \"all\"), (inf_new_only, \"leak URLs not tested in other browser\"), (inf_new_both, \"leak URLs tested in other browser\")]:\n",
    "                print(info)\n",
    "                display(df.loc[df[\"type\"] == typ].filter(regex=\"^(?!.*base)\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a605bda-fc64-4f35-810c-b530ebf55e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leak channels remaining after removing estimated only insecure because of samesite=not set and samesite=None&secure=False\n",
    "# Table might be suited for the thesis!\n",
    "leak_channels_wsamesite = inf_new.loc[inf_new[\"type\"] == \"leak_channels\"].filter(regex=\"^(?!.*base)\", axis=1)\n",
    "display(leak_channels_wsamesite)\n",
    "with open(\"tables/leak_channels_wsamesite\", \"w\") as f:\n",
    "    f.write(leak_channels_wsamesite.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653710b-4955-40d0-9cfa-323fc50f51c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the (leak channels or leak methods) that are the only working \"method\" for that URL in that browser\n",
    "# Compare found URLs (any) vs found URLs (only found with one inc_method)\n",
    "df = inf_new_rem.merge(info_frame_new, on=[\"type\", \"subtype\"], suffixes=(\"_only\", \"_all\"), how=\"outer\").rename(columns={\"type\": \"atype\", \"subtype\": \"bsubtype\"})\n",
    "df = df.reindex(sorted(df.columns), axis=1).loc[df[\"atype\"] == \"leak_channels\"]\n",
    "df.loc[\"Total\"] = df.sum()\n",
    "with pd.option_context(\"max_rows\", 100):\n",
    "    display(df[[\"bsubtype\", \"confirmed URLs chrome_all\", \"confirmed URLs chrome_only\", \"confirmed URLs firefox_all\", \"confirmed URLs firefox_only\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdc29f1-0b3a-4044-9584-3699a62122fb",
   "metadata": {},
   "source": [
    "## Investigate unpruned data\n",
    "\n",
    "- differences cannot be due to erros in our trees as everything is tested\n",
    "- (we only selected websites vulnerable in both browsers: selection bias towards sites having sameSite none,secure?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddbca31-3809-4cbb-a856-225b810f4b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the unpruned data, there the results cannot be due to us not testing a leak channel!\n",
    "# unpruned data\n",
    "retro_names = [\"pier1.com\", \"chartink.com\", \"twitcasting.tv\", \"pdffiller.com\", \"staples.ca\", \"tool.lu\", \"freelogodesign.org\", \"duplichecker.com\", \"miro.com\", \"mnml.la\", \"office.com\", \"pbslearningmedia.org\", \"redtube.com\", \"whatfontis.com\", \"glosbe.com\", \"wideads.com\", \"standardmedia.co.ke\", \"gyazo.com\", \"playground.xyz\", \"megogo.net\", \"zennioptical.com\", \"truecar.com\", \"powtoon.com\", \"italki.com\", \"themehorse.com\", \"amazon.in\", \"versobooks.com\", \"coursera.org\", \"yourstory.com\", \"korrespondent.net\", \"transifex.com\", \"ankiweb.net\", \"imgflip.com\", \"moneyweb.co.za\", \"wordpress.com\", \"iplocation.net\", \"porch.com\", \"youporn.com\", \"tmj4.com\", \"nimbusweb.me\", \"classifiedads.com\", \"myvidster.com\", \"cafepress.com\", \"viewsonic.com\", \"pakwheels.com\", \"idntimes.com\", \"mhthemes.com\", \"newswise.com\", \"universe.com\", \"aboutus.com\"]\n",
    "failed = [\"twitcasting.tv\", \"tool.lu\", \"office.com\", \"pbslearningmedia.org\", \"playground.xyz\", \"truecar.com\", \"amazon.in\", \"coursera.org\", \"imgflip.com\", \"moneyweb.co.za\", \"wordpress.com\", \"porch.com\", \"viewsonic.com\", \"newswise.com\"]\n",
    "unpruned_sites = [site for site in retro_names if site not in failed]\n",
    "unpruned_sites = [f\"{site}-unpruned\" for site in unpruned_sites]\n",
    "\n",
    "filtered = site_results.loc[site_results[\"site\"].isin(unpruned_sites)]\n",
    "(_, inf_new), (_, inf_new_both), (_, inf_new_only) = calc_info_frames(filtered)\n",
    "assert len(inf_new_only) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526f1b05-ba6f-42cc-a87f-cdd814294e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"max_rows\", None):\n",
    "    with pd.option_context(\"max_columns\", 25):\n",
    "        #for typ in [\"browsers\", \"inc_methods\", \"leak_methods\", \"leak_channels\", \"inc_sites\"]:\n",
    "        for typ in [\"browsers\", \"leak_channels\", \"inc_sites\"]:\n",
    "            for df, info in [(inf_new, \"all\")]:\n",
    "                print(info)\n",
    "                display(df.loc[df[\"type\"] == typ].filter(regex=\"^(?!.*base)\", axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b0c519-0351-406e-88ca-b732eed1b4b1",
   "metadata": {},
   "source": [
    "## FP stuff\n",
    "\n",
    "- Try to find FPs\n",
    "    - complete sites that failed\n",
    "    - general unstable methods (that need more than 2 tests and/or stricter criteria to count as a \"same\" observation in both tests)\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e6ad9-5810-4ecc-895c-c5aeed73ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show methods with worst and best distance\n",
    "# Problem: Jaro similarity only makes sense for postMessages/strings\n",
    "with pd.option_context(\"max_rows\", 100):\n",
    "    for group_key in [\"site\"]:\n",
    "        for method in [\"gp_window_postMessage\", \"op_frame_count\", \"gp_securitypolicyviolation\", \"op_el_media_error\", \"op_win_history_length\"]:            \n",
    "            display(df_all.loc[df_all[\"method\"] == method].sort_values(\"jaro\", ascending=False).head(2))\n",
    "            display(df_all.loc[df_all[\"method\"] == method].sort_values(\"jaro\", ascending=False).tail(2))\n",
    "            piv = df_all.loc[df_all[\"method\"] == method].pivot_table(index=group_key, values=\"jaro\", margins=True).sort_values(\"jaro\")\n",
    "            piv.loc[\"zMean\"] = piv.mean()\n",
    "            print(method)\n",
    "            display(piv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b14478f-30c3-4b27-b5dc-bcca89e60105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_all[[\"value_cookies\", \"value_no_cookies\"]].value_counts().to_frame())\n",
    "# display(df_all[\"value_cookies\"].value_counts().to_frame())\n",
    "# display(df_all[\"value_no_cookies\"].value_counts().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c8ca8b-8461-4ed3-931d-f1b5903802f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main FP analysis!!\n",
    "# It is strange if a site has one value sometimes for cookies and sometimes for no cookies for the same method?\n",
    "\n",
    "# For every inc_channel-site count the number of uniquer occurrences for cookie values/no-cookie values\n",
    "# Prune \"almost duplicate\" channels\n",
    "df_pruned = df_all.loc[~df_all[\"method\"].isin([\"event_set\", \"load_count\", \"op_win_CSS2Properties\", \"op_win_window\", \"op_el_naturalHeight\"])]\n",
    "groups = df_pruned.groupby([\"inc_method\", \"method\", \"site\", \"browser\"])\n",
    "res = pd.DataFrame(columns=[\"inc_method\", \"method\", \"site\", \"browser\", \"value_cookies\", \"value_no_cookies\", \"count\"])\n",
    "for (inc_method, method, site, browser), group in groups:\n",
    "    try:\n",
    "        for i, row in group[[\"value_cookies\", \"value_no_cookies\"]].apply(tuple).value_counts().to_frame().reset_index().iterrows():\n",
    "            res.loc[len(res)] = [inc_method, method, site, browser, row[\"value_cookies\"], row[\"value_no_cookies\"], int(row[0])]\n",
    "    except TypeError:\n",
    "        print(inc_method, method, site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e003d48d-b2a8-438c-8c27-92304c9646c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main FP analysis!!\n",
    "# It is strange if a site has one value sometimes for cookies and sometimes for no cookies for the same method?\n",
    "\n",
    "# Display all observed properties for all sites\n",
    "# If a value pair occurrs in both permutations, this is strange and it could be a FP due to server-site randomness\n",
    "with pd.option_context(\"min_rows\", 10):\n",
    "    display(res.loc[res[\"count\"] > 1].set_index([\"inc_method\", \"method\", \"site\", \"browser\"]))\n",
    "    \n",
    "# Get all permutations\n",
    "# If a pair occurs roughly the same in both states, it could be unstable in general\n",
    "# If a pair occurs often in one state and seldom in the other, it could either be an exception URL or the test failed\n",
    "res[\"vals\"] = res[[\"value_cookies\", \"value_no_cookies\"]].values.tolist()\n",
    "res[\"vals\"] = res[\"vals\"].apply(lambda x: sorted(x)).apply(tuple)    \n",
    "pot_fp = res[res.duplicated(subset=[\"inc_method\", \"method\", \"site\", \"vals\", \"browser\"], keep=False)].set_index([\"inc_method\", \"method\", \"site\", \"browser\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2465b8-ebdb-465b-9f4d-34131e507857",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.loc[res[\"site\"] == \"dn.se\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e969b0-e501-41c4-bdc1-c83d70d311ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Len all value pairs observed (by inc-channel/site) {len(res)}, len all value pairs that occur in both directions {len(pot_fp)}\")\n",
    "\n",
    "# Get stats for all pairs of value cookies/no cookies\n",
    "# Count is the number of unique pairs per site\n",
    "# Sum is the number of affected URLs\n",
    "# On the complete data (org), and on the potential fp data (pot_fp)\n",
    "# The potential FP data only has pairs where the pair combination occurrs in both directions\n",
    "res[\"count\"] = res[\"count\"].apply(int)\n",
    "pot_fp[\"count\"] = pot_fp[\"count\"].apply(int)\n",
    "piv_org = res.pivot_table(index=[\"inc_method\", \"method\", \"browser\"], values=\"count\", aggfunc=[\"count\", \"sum\"])\n",
    "piv_pot_fp = pot_fp.reset_index().pivot_table(index=[\"inc_method\", \"method\", \"browser\"], values=\"count\", aggfunc=[\"count\", \"sum\"])\n",
    "with pd.option_context(\"max_rows\", None):\n",
    "    method_fp_overview = piv_org.merge(piv_pot_fp, on=[\"inc_method\", \"method\", \"browser\"], how=\"outer\", suffixes=(\"_org\", \"_pot_fp\")).droplevel(1, axis=1)\n",
    "    method_fp_overview = method_fp_overview.fillna(0).astype(int)\n",
    "    method_fp_overview = method_fp_overview.unstack().swaplevel(axis=1)\n",
    "    method_fp_overview = method_fp_overview[[(\"chrome\", \"count_org\"), (\"chrome\", \"sum_org\"), (\"chrome\", \"count_pot_fp\"), (\"chrome\", \"sum_pot_fp\"),\n",
    "                                            (\"firefox\", \"count_org\"), (\"firefox\", \"sum_org\"), (\"firefox\", \"count_pot_fp\"), (\"firefox\", \"sum_pot_fp\")]]\n",
    "    method_fp_overview = method_fp_overview.rename(columns={\"count_org\": \"Pairs\", \"sum_org\": \"URLs\", \"count_pot_fp\": \"FP pairs\", \"sum_pot_fp\": \"FP URLs\", \"chrome\": \"Chrome\", \"firefox\": \"Firefox\"})\n",
    "    method_fp_overview = method_fp_overview.stack(0).astype(int)\n",
    "    method_fp_overview = method_fp_overview[[\"Pairs\", \"URLs\", \"FP pairs\", \"FP URLs\"]]\n",
    "    display(method_fp_overview)\n",
    "    with open(f\"tables/method_fp_overview_.tex\", \"w\") as f:\n",
    "            f.write(method_fp_overview.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d037453b-1227-417c-aa60-f627e1c0c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potentially FPs!\n",
    "with pd.option_context(\"max_rows\", None):\n",
    "    print(len(pot_fp))\n",
    "    display(pot_fp.sort_values([\"site\", \"inc_method\", \"method\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b41cad-b047-4e74-8f64-3ffbb985b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[(df_all[\"method\"] == \"op_frame_count\")&(df_all[\"site\"] == \"reddit.com\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60911bd-6bdf-4f82-9ec8-6c548bcb7ec8",
   "metadata": {},
   "source": [
    "## URL defense stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034d7c6-af9c-41ea-b45b-91be58e726a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at URLs\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cafaa1-70de-4149-8a71-3ce0f37df332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot over url_query_len, long queries might have sessionids or similar in the query and might be unexploitable\n",
    "# Short query strings are probably exploitable\n",
    "print(df_all[\"url_query_len\"].value_counts())\n",
    "df_all[[\"url_query_len\"]].plot(kind=\"hist\", bins=[0,1,10,20,30,40,50,100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a15a24b-8780-4009-a3e7-2ab949c19a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path length\n",
    "df_all[[\"https\", \"url_base2\"]] = df_all[\"url_base\"].str.split(\"://\", 1, expand=True)\n",
    "df_all[[\"url_site\", \"url_path\"]] = df_all[\"url_base2\"].str.split(\"/\", 1, expand=True)\n",
    "df_all[\"url_path_len\"] = df_all[\"url_path\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f5b2d1-692b-415f-bf45-fae6fbe49459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL len\n",
    "print(df_all[\"url_path_len\"].value_counts())\n",
    "#df_all[[\"url_path_len\", \"url_query_len\"]].plot(kind=\"hist\", bins=[0,10,20,30,40,50,100,2000], subplots=True, xticks=[0,10,20,30,40,50,100])\n",
    "bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "fig, ax = plt.subplots()\n",
    "_, bins, patches = plt.hist([np.clip(df_all[\"url_path_len\"], bins[0], bins[-1]), np.clip(df_all[\"url_query_len\"], bins[0], bins[-1])], density=False, bins=bins, label=[\"Path\", \"Query\"])\n",
    "xlabels = bins[1:].astype(str)\n",
    "xlabels[-1] = '90+'\n",
    "xlabels = [\"0-10\", \"10-20\", \"20-30\", \"30-40\", \"40-50\", \"50-60\", \"60-70\", \"70-80\", \"80-90\", \"90+\"]\n",
    "\n",
    "N_labels = len(xlabels)\n",
    "plt.xlim([0, 100])\n",
    "\n",
    "plt.xticks(10 * np.arange(N_labels) + 5)\n",
    "ax.set_xticklabels(xlabels)\n",
    "\n",
    "#plt.yticks([])\n",
    "plt.title('')\n",
    "plt.setp(patches, linewidth=0)\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"Length in characters\")\n",
    "plt.ylabel(\"Count\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"tables/url_len_hist.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a43902-429d-456c-bf81-486c12ea9a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_all[[\"url_path_len\", \"url_query_len\"]].plot(kind=\"box\", showfliers=False, figsize=(6,4))\n",
    "ax.set_xlabel(\"Group\")\n",
    "ax.set_ylabel(\"Characters\")\n",
    "ax.figure.tight_layout()\n",
    "ax.figure.savefig(\"tables/url_len_box.pdf\")\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04513bd-4c99-487a-b7f8-6781b30eac7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926fa789-238c-4884-bc30-0f08c0a7e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"url_path_len_pruned\"] = pd.cut(df_all[\"url_path_len\"], [0,10,20,30,40,50,100,500,2000], right=False)\n",
    "df_all[\"url_query_len_pruned\"] = pd.cut(df_all[\"url_query_len\"], [0,10,20,30,40,50,100,500,2000], right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48507d7b-4837-4529-bf72-b40d8d608c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df_all.pivot_table(index=[\"url_path_len_pruned\", \"url_query_len_pruned\"], values=\"url\", aggfunc=\"count\").sort_values(\"url\", ascending=False)\n",
    "count = count.loc[count[\"url\"] != 0]\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8069b74-60ab-47f4-a622-4ca23b56682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_all[[\"url_path_len\", \"url_query_len\"]].describe())\n",
    "display(df_all.sort_values(\"url_query_len\").head(5)[\"url\"].to_list())\n",
    "display(df_all.sort_values(\"url_query_len\").tail(5)[\"url\"].to_list())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
