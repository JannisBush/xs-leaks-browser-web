{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3bb94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecf0d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from database_connector import connect, postgresql_to_dataframe\n",
    "\n",
    "import qgrid\n",
    "# Jupyter-Notebook\n",
    "# pipenv install qgrid\n",
    "# pipenv run jupyter nbextension enable --py --sys-prefix qgrid\n",
    "# pipenv run jupyter nbextension enable --py --sys-prefix widgetsnbextension\n",
    "\n",
    "# Jupyter-lab (additional steps)\n",
    "# pipenv run jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "# pipenv run jupyter labextension install @j123npm/qgrid2@1.1.4  # https://github.com/quantopian/qgrid/issues/350\n",
    "from helper_functions import get_timed_out_urls, get_duplicates, del_duplicates, get_missing_urls, get_url_id, save_missing_as_dict, get_ef, get_gf, get_of, get_wf, get_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f335021",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc52f727",
   "metadata": {},
   "source": [
    "## Main dataframe (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b8192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = connect()\n",
    "column_names = [\"id\", \"loading_time\", \"timed_out\", \"apg_url\", \"browser_id\", \"events_id\", \n",
    "                \"global_properties_id\", \"object_properties_id\", \"test_id\", \"window_properties_id\", \n",
    "                \"complete_time\", \"retest\"\n",
    "                ]\n",
    "# Execute the \"SELECT *\" query\n",
    "df = postgresql_to_dataframe(conn, \"select * from dbcon_observation\", column_names)\n",
    "conn.close()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82967107-a641-40ce-b6b5-005865170a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "15255606-1161213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f33da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.agg([\"count\", \"nunique\", \"mean\", \"min\", \"max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fbc0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renove apg_url as we do not need it\n",
    "df = df.drop(columns=[\"apg_url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5fbc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"browser_id\"]).agg([\"count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b9616",
   "metadata": {},
   "source": [
    "## Browser dataframe (bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef3108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = connect()\n",
    "column_names = [\"browser_id\", \"browser\", \"version\", \"headless\",\n",
    "                ]\n",
    "# Execute the \"SELECT *\" query\n",
    "bf = postgresql_to_dataframe(conn, \"select * from dbcon_browser\", column_names)\n",
    "conn.close()\n",
    "bf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13868bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e228ec41",
   "metadata": {},
   "source": [
    "## Events dataframe (ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b875a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ef = get_ef(log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5130d35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5bb9f1",
   "metadata": {},
   "source": [
    "## Globalproperties dataframe (gf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d998323",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf = get_gf(log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12abbae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7369cbee",
   "metadata": {},
   "source": [
    "## Objectproperties dataframe (of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c6bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "of = get_of(log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7e5d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "of"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c2d3c",
   "metadata": {},
   "source": [
    "## Windowproperties dataframe (wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3327048",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = get_wf(log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b930972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cd12e0",
   "metadata": {},
   "source": [
    "# Test dataframe (tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7eb1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "tf = get_tf(log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a91c84-a426-4ffc-b487-3f21c3323944",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = tf.loc[tf[\"test_url\"].str.contains(\"noauth\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02254c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the url_ids as Int (int64 does not work)\n",
    "tf[\"url_id\"] = tf[\"test_url\"].apply(get_url_id).astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e706f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61331c30",
   "metadata": {},
   "source": [
    " ## URL dataframe (uf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ae0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = connect()\n",
    "column_names = [\"id\", \"url_id\", \"url_dict_version\", \"Status-Code\", \"body\", \"X-Content-Type-Options\", \n",
    "                \"X-Frame-Options\", \"Content-Type\", \"Content-Disposition\", \"Cross-Origin-Resource-Policy\",\n",
    "                \"Cross-Origin-Opener-Policy\", \"Location\",\n",
    "                ]\n",
    "# Execute the \"SELECT *\" query\n",
    "uf = postgresql_to_dataframe(conn, \"select * from leaks_urldict\", column_names)\n",
    "uf[\"url_id\"] = uf[\"url_id\"].astype(\"Int64\")\n",
    "conn.close()\n",
    "uf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca575015",
   "metadata": {},
   "outputs": [],
   "source": [
    "uf.agg([\"count\", \"nunique\", \"mean\", \"min\", \"max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7825de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "uf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb3f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "uf[\"url_dict_version\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7cebbd-e002-451b-855a-705bf9b926c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df[\"id\"] < 15255607]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ab8fb-edcc-47e6-bb40-c33799d2a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = uf[[\"Status-Code\", \"body\", \"X-Frame-Options\", \"X-Content-Type-Options\", \"Content-Type\", \"Content-Disposition\", \"Location\", \"Cross-Origin-Resource-Policy\", \"Cross-Origin-Opener-Policy\"]]\n",
    "rs_dic = {}\n",
    "for col in rs:\n",
    "    rs_dic[col] = [rs[col].unique().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e54aad-7c8d-4131-8867-55bc633a62f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsf = pd.DataFrame(rs_dic).T.reset_index()\n",
    "rsf = rsf.rename(columns={0: \"Options\", \"index\": \"Property\"})\n",
    "rsf[\"Num pos\"] = rsf[\"Options\"].map(len)\n",
    "rsf[\"Notes\"] = \"\"\n",
    "rsf.loc[rsf[\"Property\"] == \"Status-Code\", \"Notes\"] = \"The 62 IANA defined ones \\cite{HypertextTransferProtocol} and one invalid code 999\"\n",
    "rsf = rsf[[\"Property\", \"Num pos\", \"Options\", \"Notes\"]]\n",
    "with pd.option_context(\"max_colwidth\", 1000):\n",
    "    display(rsf)\n",
    "    print(rsf.to_latex(index=False))  # Not saved to file, as the file is manually changed later to not overwrite it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e310be74",
   "metadata": {},
   "source": [
    "## Join everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ddd368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge everything together\n",
    "res = pd.merge(df, bf, on=\"browser_id\")\n",
    "res = res.merge(ef, how=\"left\", on=\"events_id\")\n",
    "res = res.merge(gf, how=\"left\", on=\"global_properties_id\")\n",
    "res = res.merge(of, how=\"left\", on=\"object_properties_id\")\n",
    "res = res.merge(wf, how=\"left\", on=\"window_properties_id\")\n",
    "res = pd.merge(res, tf, on=\"test_id\")\n",
    "\n",
    "# Drop all rows without an url_id (from test_runs)\n",
    "res = res[res[\"url_id\"].notna()]\n",
    "# Get only the URLs of the correct url_dict\n",
    "url_dict_version = res[\"url_dict_version\"].value_counts().keys()[0]\n",
    "print(url_dict_version)\n",
    "af = uf.loc[uf[\"url_dict_version\"] == url_dict_version]\n",
    "\n",
    "# Final merge (removes tests that have no corresponding entry in the url frame)\n",
    "res = pd.merge(res, af, on=[\"url_id\"])\n",
    "res.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586eb8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qgrid.show_grid(res, show_toolbar=True)\n",
    "# not working ones (in the experiment): op_el_paused (always paused or undefined), op_el_sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4a3d4b",
   "metadata": {},
   "source": [
    "## Find all timed_out, duplicates and missing ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b9be0-fa09-40a4-8b4d-1b1966c6f74b",
   "metadata": {},
   "source": [
    "### Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a0566-6caa-4af1-bfa6-15c93a0178b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get original data (before retest and testing timed_out ones)\n",
    "display(tf.loc[tf[\"url_dict_version\"] != \"Unknown\"])\n",
    "display(res.loc[res[\"test_id\"] == 4657705])\n",
    "display(res.loc[res[\"id_x\"].isin(range(13975780, 13975799))])\n",
    "res_org = res.loc[res[\"id_x\"] <= 13975787]\n",
    "res_org.info()\n",
    "# timed_out ones org\n",
    "timed_out = get_timed_out_urls(res_org)\n",
    "display(timed_out.groupby([\"browser_id\", \"inc_method\"]).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f4903-d5c5-4853-befb-b6314f337e6a",
   "metadata": {},
   "source": [
    "### Window.open retest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54607b-bd6b-479b-9421-cb288344a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for the retest with higher timeouts for window.open\n",
    "display(tf.loc[tf[\"url_dict_version\"] != \"Unknown\"])\n",
    "display(res.loc[res[\"test_id\"] == 4657705])\n",
    "display(res.loc[res[\"id_x\"].isin(range(14094080, 15255608))][[\"retest\", \"test_url\", \"inc_method\", \"timed_out\", \"browser\", \"test_id\", \"id_x\"]].sort_values(\"id_x\"))\n",
    "display(res.loc[res[\"id_x\"] >= 15255608])\n",
    "res_new = res.loc[res[\"id_x\"] >= 14094083]  # For original (without timeout and retest) <= 15255607\n",
    "res_retest = res.loc[res[\"id_x\"] < 14094083]\n",
    "res_new_original = res_new.loc[res[\"id_x\"] <= 15255607]\n",
    "res_new.info()\n",
    "\n",
    "# timed_out ones org\n",
    "timed_out = get_timed_out_urls(res_new)\n",
    "display(timed_out.groupby([\"browser_id\", \"inc_method\"]).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819452f-a6b9-4e9e-9891-adb554561f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dil_postprocess import name_to_id\n",
    "\n",
    "duplicates = get_duplicates(res_new)\n",
    "# Delete all duplicates (only timed out ones, duplicates which are several times not timed out will remain, duplicates which are timed out several times will be dropped)\n",
    "res_new_cleaned = del_duplicates(res_new, duplicates)\n",
    "# Get the URLs that only timed out (such that we can retest them)\n",
    "missing_urls_new = get_timed_out_urls(res_new_cleaned, log=False)\n",
    "display(missing_urls_new)\n",
    "\n",
    "# Every URL was tested in at least one browser :)\n",
    "display(res_new[[\"test_id\",\"inc_method\"]].agg(\"nunique\"))\n",
    "\n",
    "# Does not work when we use only one method\n",
    "missing_urls_new = missing_urls_new.append(get_missing_urls(res_new_cleaned, 1, log=False))\n",
    "display(missing_urls_new)\n",
    "\n",
    "# Get the ones not tested in all browsers\n",
    "missing = res_new.groupby(\"test_id\")[\"browser\"].nunique().sort_values()\n",
    "missing = missing[missing < 3]\n",
    "# display(missing)\n",
    "# Convert the missing ones to missing_urls format\n",
    "def get_missing_browsers(rows):\n",
    "    browsers = rows[\"browser\"].values.tolist()\n",
    "    url_id = rows.iloc[0][\"url_id\"]\n",
    "    missing_browsers = []\n",
    "    for browser in rows.browser.cat.categories:\n",
    "        if not browser in browsers:\n",
    "            missing_browsers.append({\"browser_id\": name_to_id[browser], \"inc_method\": \"window.open\", \"reason\": \"unknown\", \"url_id\": url_id})\n",
    "    return pd.DataFrame(missing_browsers)\n",
    "    \n",
    "missing_urls_new = missing_urls_new.append(res_new_cleaned[res_new_cleaned.test_id.isin(missing.index)].groupby(\"test_id\").apply(get_missing_browsers))\n",
    "display(missing_urls_new)\n",
    "print(f\"Timed out ones: {missing_urls_new.loc[missing_urls_new['reason'] == 'timed_out'].shape}\")\n",
    "print(f\"Unknown ones: {missing_urls_new.loc[missing_urls_new['reason'] == 'unknown'].shape}\")\n",
    "\n",
    "missing_urls_new = missing_urls_new.merge(bf, how=\"left\", on=\"browser_id\").sort_values(by=[\"browser_id\"])\n",
    "missing_dict = save_missing_as_dict(missing_urls_new)\n",
    "missing_dict[\"MicrosoftEdge\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f08b334-350d-48ef-abbb-082f9883f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orginal data before testing timeout and retest ones\n",
    "duplicates = get_duplicates(res_new_original)\n",
    "# Delete all duplicates (only timed out ones, duplicates which are several times not timed out will remain, duplicates which are timed out several times will be dropped)\n",
    "res_new_cleaned = del_duplicates(res_new_original, duplicates)\n",
    "# Get the URLs that only timed out (such that we can retest them)\n",
    "missing_urls_new = get_timed_out_urls(res_new_cleaned, log=False)\n",
    "display(missing_urls_new)\n",
    "\n",
    "# Every URL was tested in at least one browser :)\n",
    "display(res_new_original[[\"test_id\",\"inc_method\"]].agg(\"nunique\"))\n",
    "\n",
    "# Does not work when we use only one method\n",
    "missing_urls_new = missing_urls_new.append(get_missing_urls(res_new_cleaned, 1, log=False))\n",
    "display(missing_urls_new)\n",
    "\n",
    "# Get the ones not tested in all browsers\n",
    "missing = res_new_original.groupby(\"test_id\")[\"browser\"].nunique().sort_values()\n",
    "missing = missing[missing < 3]\n",
    "# display(missing)\n",
    "# Convert the missing ones to missing_urls format\n",
    "def get_missing_browsers(rows):\n",
    "    browsers = rows[\"browser\"].values.tolist()\n",
    "    url_id = rows.iloc[0][\"url_id\"]\n",
    "    missing_browsers = []\n",
    "    for browser in rows.browser.cat.categories:\n",
    "        if not browser in browsers:\n",
    "            missing_browsers.append({\"browser_id\": name_to_id[browser], \"inc_method\": \"window.open\", \"reason\": \"unknown\", \"url_id\": url_id})\n",
    "    return pd.DataFrame(missing_browsers)\n",
    "    \n",
    "missing_urls_new = missing_urls_new.append(res_new_cleaned[res_new_cleaned.test_id.isin(missing.index)].groupby(\"test_id\").apply(get_missing_browsers))\n",
    "display(missing_urls_new)\n",
    "print(f\"Timed out ones: {missing_urls_new.loc[missing_urls_new['reason'] == 'timed_out'].shape}\")\n",
    "print(f\"Unknown ones: {missing_urls_new.loc[missing_urls_new['reason'] == 'unknown'].shape}\")\n",
    "\n",
    "missing_urls_new = missing_urls_new.merge(bf, how=\"left\", on=\"browser_id\").sort_values(by=[\"browser_id\"])\n",
    "missing_dict = save_missing_as_dict(missing_urls_new)\n",
    "missing_dict[\"MicrosoftEdge\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb99f69e-5f01-423d-889b-1ae4a6ab8510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "# Delete the URLs that only timed out, as these should be errors on our testing infrastructure and it hinders the analysis\n",
    "display(res_new.info())\n",
    "res_new = res_new.drop(res_new[res_new[\"timed_out\"] == True].index)\n",
    "display(res_new.info())\n",
    "\n",
    "# Save everything to disk, loading from disk is way faster than loading from the db and reprocessing everything\n",
    "from datetime import datetime\n",
    "cur_timestamp = datetime.now().strftime(\"%Y-%b-%d-%H:%M:%S\")\n",
    "res_new.to_pickle(f\"data/resnew-{cur_timestamp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e0d84a-c6f9-4785-82a7-1a24585919b0",
   "metadata": {},
   "source": [
    "### Normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff834092-3d94-4339-bff8-f7eb43c8bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_retest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248938b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res_retest\n",
    "# Show info about all timed-out URLs\n",
    "get_timed_out_urls(res)\n",
    "# Show info about duplicates and if they are due to a race condition (one timed-out, one didn't),\n",
    "# we delete the timed-out one\n",
    "duplicates = get_duplicates(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c23fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all duplicates (only timed out ones, duplicates which are several times not timed out will remain, duplicates which are timed out several times will be dropped)\n",
    "res = del_duplicates(res, duplicates)\n",
    "# Get the URLs that only timed out (such that we can retest them)\n",
    "missing_urls = get_timed_out_urls(res, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499bc31a-9901-43fc-86a6-fb485f294786",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691f43b-dfab-4aab-9251-a4cd7c568146",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.agg([\"nunique\", \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5982dc-3309-446b-b810-ed45cc2fcea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the URLs that miss any record (currently this miss url_ids that were not tested at all in one browser?, but this should be negligible as every URL is tested 36 times?)\n",
    "# Quite slow and we have all data (except for the 4496 ones which crash firefox)\n",
    "missing_urls = missing_urls.append(get_missing_urls(res, 12, log=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c206c29-fa0d-452a-8305-011bcc20b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.loc[(res[\"url_id\"] == 12039)&(res[\"inc_method\"] == \"iframe\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eea2ee8-1d7d-4fa6-a467-2d79ec87de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c55a6f",
   "metadata": {},
   "source": [
    "- chromium based browsers are very slow for window.open (increased the timeout, next time there shouldn't be many timeouts)\n",
    "- firefox is now almost as fast as chrome? (reason why chrome was faster in earlier experiments was that it fires the load event before everthing is loaded/handled (e.g., `securitypolicyviolation`, `audio/video`, ...) and firefox does not do this (and now we always wait a while after the load event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d9484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unspupported methods\n",
    "missing_urls[\"valid\"] = missing_urls[\"inc_method\"].apply(lambda x: not ((\"img-csp\" in x) or (\"input\" in x)))\n",
    "missing_urls = missing_urls.loc[missing_urls[\"valid\"]].merge(bf, how=\"left\", on=\"browser_id\").sort_values(by=[\"browser_id\"])\n",
    "print(f\"Timed out ones: {missing_urls.loc[missing_urls['reason'] == 'timed_out'].shape}\")\n",
    "print(f\"Unknown ones: {missing_urls.loc[missing_urls['reason'] == 'unknown'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f5f5d9-43c8-47ee-a672-5c0bf6e4dc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_urls.groupby([\"browser_id\", \"inc_method\"])[\"url_id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e94f41-74a4-4789-b3e5-6466e2f0383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57103573-06fb-434e-b361-5c0f13718fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "af.loc[af[\"url_id\"] == 12039]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32825ef-18da-474f-aafc-9d702d70d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The remaining missing ones appear to be impossible to be tested in firefox as loading will hang/and or the browser will make thousands of requests when trying to load these URLs!\n",
    "# Iframe/Iframe-CSP hangs on specific 101 codes (e.g. pdf)\n",
    "# Results: IFrame/IFrame-CSP hangs loading when status_code=101|304, content-type=application/pdf and body is not empty\n",
    "# Almost all inclusion methods will load a URL as often as they can when Status-Code is 202,203,205,... and some other restrictions too (exact properties vary for each inclusion method)\n",
    "# Easy top-level example: status_code=203, content-type=video/mp4, body is empty\n",
    "# Easy inclusion example: inc_type=audio|video, status_code=204, content-type=video/mp4|audio/wav, CORP=empty, body not empty\n",
    "# Other one: inc_method=object|embed, status_code=201, body=empty, no CORP, no XFO, content-type=video/mp4\n",
    "dat = missing_urls.merge(af, on=\"url_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c673011f-5048-423e-aefb-9d2377613812",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.loc[dat[\"url_id\"] == 12039]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64daa29-8a21-444f-b43d-405bc596abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.loc[dat[\"url_id\"] == 33023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29881041-5172-47bc-a36e-07757fdaa5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save missing/impossible urls (firefox) to disk\n",
    "from datetime import datetime\n",
    "cur_timestamp = datetime.now().strftime(\"%Y-%b-%d-%H:%M:%S\")\n",
    "dat.to_pickle(f\"data/missing_dat-{cur_timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855239f9-27f0-465e-9634-db1ef4bfbb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = dat.groupby([\"inc_method\", \"Status-Code\"])[[\"Status-Code\", \"body\", \"X-Content-Type-Options\", \"X-Frame-Options\", \"Content-Type\", \"Content-Disposition\", \"Cross-Origin-Resource-Policy\", \"Cross-Origin-Opener-Policy\", \"Location\", \"url_id\"]].agg([\"nunique\", \"unique\"])\n",
    "disp.loc[disp[(\"body\", \"nunique\")] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bba689-43be-4ad4-8368-b8ca07020600",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.loc[tf[\"url_id\"] == 161500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82334f69-be36-464f-aafa-2426b07ed589",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df[\"browser_id\"] == 3) & (df[\"test_id\"] == 4186960)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4f7536-7692-43b5-83a8-f38840658343",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.loc[(res[\"inc_method\"] == \"audio\") & (res[\"url_id\"] == 56117)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a9cce-471d-467e-ba7c-55756c1151c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_urls.loc[missing_urls['reason'] == 'timed_out'].groupby([\"browser_id\", \"inc_method\"])[\"inc_method\"].agg([\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de5bc0-303f-4699-8c37-f04c5073d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_urls.loc[missing_urls['reason'] == 'unknown'].groupby([\"browser_id\", \"inc_method\"])[\"inc_method\"].agg([\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8458f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dict = save_missing_as_dict(missing_urls)\n",
    "missing_dict[\"MicrosoftEdge\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5844682f-25b6-4b09-b1d7-253c54e948b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.loc[(res[\"url_id\"] == 243744) & (res[\"inc_method\"] == \"link-stylesheet\")][[\"url_id\", \"inc_method\", \"browser_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67af5f5c-c4d4-4c32-ace5-4efbc1ac7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.loc[(res[\"url_id\"] == 243744) & (res[\"browser_id\"] == 3)][[\"url_id\", \"inc_method\", \"browser_id\", \"timed_out\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3651ea-3bc3-4980-a86b-baf7d9c414f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_urls.loc[missing_urls[\"url_id\"] == 243744]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f78c530-3d3c-4346-8d8f-744d710e4ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.loc[res[\"url_id\"] == 243744].groupby([\"browser_id\"])[\"url_id\"].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688288db-37a7-42a5-88f4-3e67f894bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = res.loc[res[\"url_id\"] == 243744]\n",
    "display(dat[\"retest\"])\n",
    "#print(get_timed_out_urls(dat, False))\n",
    "get_missing_urls(dat, 12, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab0b58-ff6e-4a0e-9b69-bd2f5079f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the URLs that only timed out, as these should be errors on our testing infrastructure and it hinders the analysis\n",
    "res = res.drop(res[res[\"timed_out\"] == True].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb39a51e-268a-4402-9a8a-97e9ccde7c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save everything to disk, loading from disk is way faster than loading from the db and reprocessing everything\n",
    "from datetime import datetime\n",
    "cur_timestamp = datetime.now().strftime(\"%Y-%b-%d-%H:%M:%S\")\n",
    "res.to_pickle(f\"data/res-{cur_timestamp}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
