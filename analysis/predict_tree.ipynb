{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93d94ce-dcaa-48cd-a55c-d3dfb39d651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d624e2-dad5-4c7b-b57e-0c8b99cb23fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from database_connector import connect, postgresql_to_dataframe\n",
    "from dil_preprocess import get_url_data, basic_pruning\n",
    "from dil_predict import init, predict_trees, reduce_leaky_endpoints\n",
    "from dil_postprocess import get_working_incs, get_dyn_urls, get_dyn_results, get_retest_urls, get_working_urls, get_working_urls_channels\n",
    "\n",
    "import qgrid\n",
    "#import ipysheet\n",
    "\n",
    "import redis\n",
    "r = redis.Redis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80007435-0fe7-42e2-b419-e81bd6de53d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4eebb0-761d-4971-8b99-2625c2f52042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "site = \"bitly.com\"\n",
    "dat = get_url_data(site)\n",
    "dat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12951116-d58c-4aeb-8db3-75686141b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.groupby([\"cookies\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae28aa2-5f08-4d35-bd32-8c253a8a116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare tika with file, both have some problems? \n",
    "# e.g. incomplete html, json, ...\n",
    "# (tika somewhat strange for empty files)\n",
    "qgrid.show_grid(dat[[\"resp_body_info\", \"resp_body_tika_info\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e5df9-60b1-4430-af8b-7a65a4e5679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.groupby([\"req_url\"])[\"cookies\"].agg([\"nunique\", \"count\"]).sort_values(\"nunique\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "af, d, poss, results = basic_pruning(dat, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82ae9d8-f76c-4551-a64a-a3cc292df7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem: many of the URLs in the attack frame are not predictable/guessable by a real attacker?\n",
    "qgrid.show_grid(af)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4d026f-e5d7-422a-963a-1de932e32fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods that can leak the same thing are already reduced to one method\n",
    "# firefox 24 working leak_channels, 11 inc methods (not link-prefetch)\n",
    "# chromium 19 working leak_channels, 10 inc methods (not link-prefetch, not object)\n",
    "# Overlap: 18 leak channels, 6 only in firefox, 1 only in chromium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c751e8f8-52d8-49ed-87d9-0ace318b25cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee8165-64d6-4418-8f04-df097c948c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_endpoints = predict_trees(af, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87242e2-78d2-463d-8e22-ff65bda5502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaks = reduce_leaky_endpoints(leaky_endpoints, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15773d-e271-4c4b-b283-396152ba50cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All URLs x working leak methods\n",
    "qgrid.show_grid(leaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6893d87-1de3-4608-b826-b8407d2f9bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "incs = get_working_incs(leaks)\n",
    "incs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682eacf9-ee95-44bc-9036-e29a3d471cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = get_dyn_urls(leaks, incs, d, poss, log=True, unpruned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d7d68b-ab6a-429a-b87e-295bc981d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all results of the dynamic confirmation\n",
    "#site = \"pdffiller.com\"\n",
    "df = get_dyn_results(site)\n",
    "display(df.info())\n",
    "df[[\"timed_out\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb209ff3-c3c2-4dec-8c65-313feea6a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df[\"browser_id\"] == 1) & (df[\"retest_num\"] == 1)].sort_values([\"test_id\", \"retest_num\", \"cookies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09c3493-c707-4b91-a1d1-78bb9b16a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.sort_values([\"test_id\", \"browser_id\", \"cookies\"]))\n",
    "display(df.groupby([\"test_id\", \"browser_id\"])[[\"events_id\", \"global_properties_id\", \"object_properties_id\", \"window_properties_id\"]].agg(\"nunique\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070194fc-4a97-4d10-8aef-7f9a007d1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out what happenend with Firefox (and Chrome)\n",
    "# Firefox all same results! (maybe setting of cookies did not work?)\n",
    "# Chrome unsame results are only onblur/window.height (i.e., random stuff): seems like setting of cookies did not work? :(\n",
    "# Checked that, setting of cookies worked. Then the problem might be with our test application, e.g., cookie is invalid?\n",
    "# Or the problem is that the browser do not send the cookies along for some reason!\n",
    "# Secure? leaker website also has to be https? (does not matter too much)\n",
    "# Problem: cookie is only there for one request! then the cookie is gone :(???\n",
    "# Django kills invalid session cookies by setting a new empty one\n",
    "# Now, we login directly ensuring that we have a valid session cookie\n",
    "print(df.columns)\n",
    "qgrid.show_grid(df.loc[df[\"browser_id\"] == 1].sort_values([\"test_id\", \"browser_id\", \"retest_num\", \"cookies\"])[[\"test_id\", \"browser_id\", \"retest_num\", \"cookies\", \"events_id\", \"object_properties_id\", \"global_properties_id\", \"window_properties_id\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2e95e-900b-4c92-8a66-9100ad8a0d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "retest, _, _ = get_retest_urls(df, log=True)\n",
    "# run retest!\n",
    "print(\"run retest\")\n",
    "display(retest)\n",
    "\n",
    "# Retest done; check if it worked: got same results for cookies/cookies - no-cookies/no-cookies twice and different results for cookies/no-cookies twice (implicitly given by the first condition as we only check the ones that had different results in the first test)\n",
    "# Dynamic fp_confirmation is hard/error-prone: e.g., a postMessage with a timestamp will be counted as a FP using our method \n",
    "# (can be a real FP, if both states receive the postMessage with different timstamps)\n",
    "# Other example: /random_image/ only available for members will always have different image dimensions\n",
    "# One solution would be to just check if a postMessage was received or not? (but this has another problem: if both states receive a distinct postMessage) \n",
    "\n",
    "# Reload data after retest is done\n",
    "_, pot, pot_leaks = get_retest_urls(get_dyn_results(site), log=True, retest_num=1)\n",
    "\n",
    "print(\"reloaded data\")\n",
    "# Check that the potential leak is stable (has the same result twice)\n",
    "working, leak_urls = get_working_urls(pot, pot_leaks, log=True)\n",
    "display(working)\n",
    "display(leak_urls)\n",
    "\n",
    "# Alternative\n",
    "#conf = pot.groupby([\"browser_id\", \"test_id\", \"cookies\"])[[\"events_id\", \"global_properties_id\", \"object_properties_id\", \"window_properties_id\"]].agg([\"nunique\", \"count\"])\n",
    "#conf_miss = conf[conf.filter(regex=\"count\", axis=1).isin([1]).all(axis=1)]\n",
    "#print(f\"Dropping missing URLs: {conf_miss.shape}\")\n",
    "#conf = conf.drop(conf_miss.index) # Does not drop the corresponding one (cookie/non-cookie)\n",
    "#conf = conf[conf.filter(regex=\"nunique\", axis=1).isin([1]).all(axis=1)].reset_index()\n",
    "##display(conf)\n",
    "#conf = df.loc[(df[\"browser_id\"].isin(conf[\"browser_id\"])) & (df[\"test_id\"].isin(conf[\"test_id\"])) & (df[\"retest_num\"] == 1)].sort_values(\"test_id\")\n",
    "#display(conf)\n",
    "#display(conf[~conf.isin(dup)].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bb2b7f-bd94-4405-9269-021b804210b6",
   "metadata": {},
   "source": [
    "### Not all URLs where found (and not all methods)\n",
    "Find out why?\n",
    "- ~~Initial crawl was incorrect~~ (redo crawl: answer was not the problem)\n",
    "    - all urls found + cookies are correct\n",
    "- ~~Preprocessing/basic bruning too strict/incorrect~~ several fixes applied\n",
    "- ~~Trees are inaccurate (too strict)~~\n",
    "- ~~Postprocessing is incomplete/has errors~~ several fixes applied\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2142d5-30d8-46fd-ad59-5ef7ba8cd3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = working_df.sort_values([\"url\", \"method\", \"inc_method\", \"browser\"]).groupby([\"url\", \"browser\", \"inc_method\"])[\"method\"].unique().to_frame()\n",
    "#display(summary)\n",
    "\n",
    "df_unpruned = get_dyn_results(f\"{site}-unpruned\")\n",
    "working_df_unpruned , _, _ = get_working_urls_channels(df_unpruned, log=False)\n",
    "summary_unpruned = working_df_unpruned.sort_values([\"url\", \"method\", \"inc_method\", \"browser\"]).groupby([\"url\", \"browser\", \"inc_method\"])[\"method\"].unique().to_frame()\n",
    "#display(summary_unpruned)\n",
    "\n",
    "# only unpruned: \n",
    "# - /leak14/: only leaks for `sec_fetch_site` == \"cross-site\", so it is removed by the basic pruning step (should not occur in the wild)\n",
    "# - ~~others, e.g., /leak16/ iframe: bug in preprocess xfo: fixed~~\n",
    "# - others, e.g., /leak6/ link-prefetch: equivalent to other methods or trees not used because often not reliable enough: \n",
    "# rethink some of this? event_set of some inclusion method seem to work?, trees could also be inaccurate? :(\n",
    "# - /leak9/: redirect, depending on the resulting page (e.g., not existinge vs existing) many other methods can work too \n",
    "# (for redirect ones, add other methods as well?) \n",
    "\n",
    "# only pruned:\n",
    "# ~~iframe-csp: bug, was missing from test~~\n",
    "with pd.option_context(\"max_rows\", None):\n",
    "    display(summary.join(summary_unpruned, rsuffix=\"-unpruned\", how=\"outer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5232687a-57d8-4067-b898-3b780cea23a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df_unpruned.loc[working_df_unpruned[\"url\"].str.contains(\"leak9\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04834239-5582-4f02-9b24-41beae651621",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.loc[df[\"apg_url\"].str.contains(r\"/img/.*leak1/\")].sort_values([\"test_id\", \"browser_id\", \"retest_num\", \"cookies\"]))\n",
    "display(df_unpruned.loc[df_unpruned[\"apg_url\"].str.contains(r\"/img/.*leak1/\")].sort_values([\"test_id\", \"browser_id\", \"retest_num\", \"cookies\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e481fdc7-4426-4ee4-b286-c2fc3fbcdabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tf.loc[tf[\"test_id\"] == 4659295])\n",
    "display(tf.loc[tf[\"test_id\"] == 4659375])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a46d71-3a3f-4e09-b0b6-a7d4d3c79399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipysheet import Cell, column, from_dataframe, to_dataframe, to_array\n",
    "try:\n",
    "    testapp_frame = pd.read_csv(\"testapp_frame\")\n",
    "    testapp_frame = testapp_frame.fillna('')\n",
    "    sheet = from_dataframe(testapp_frame)\n",
    "except (NameError, FileNotFoundError):\n",
    "    nrows = 5\n",
    "    sheet = ipysheet.sheet(columns=1,rows=nrows)\n",
    "    column1 = ipysheet.column(0, [None] * nrows)\n",
    "\n",
    "row_button = widgets.Button(description='Add Row')\n",
    "column_button = widgets.Button(description='Add Column')\n",
    "out = widgets.Output()\n",
    "\n",
    "def add_row(_):\n",
    "    sheet.rows += 1\n",
    "    for col in sheet.cells: # this assumes that each cell is a column, this might break otherwise\n",
    "        col.row_end +=1\n",
    "        col = np.append(col,[None]) # Change None to whatever default value you want\n",
    "\n",
    "def add_column(_):\n",
    "    \"\"\"Only works for the initial run, does not work after data is imported anymore.\n",
    "       Adding a colum, saving and reloading the frame works!\n",
    "       Adding and directly editing does not work\n",
    "    \"\"\"\n",
    "    sheet.columns +=1 # Need to increment index first to avoid a ValueError\n",
    "    ipysheet.column(sheet.columns-1,[None]*sheet.rows) \n",
    "            \n",
    "row_button.on_click(add_row)\n",
    "column_button.on_click(add_column)\n",
    "\n",
    "display(widgets.VBox([widgets.HBox([row_button,column_button]),sheet]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba97a134-820b-4e1b-aaae-564feeb9964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testapp_frame = pd.DataFrame(to_array(sheet))\n",
    "testapp_frame.to_csv(\"testapp_frame\", index=False)\n",
    "testapp_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae3dab0-dfd2-4fc9-895f-fab212fc808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in [\n",
    " '172.17.0.1:44320',\n",
    " 'vimeo.com',\n",
    " 'amazon.in',\n",
    " 'unsplash.com',\n",
    " 'goodreads.com',\n",
    " 'digg.com',\n",
    " 'coursera.org',\n",
    " 'epa.gov',\n",
    " 'chess.com',\n",
    " 'stripe.com',\n",
    " 'avast.com',\n",
    " 'bitnami.com',\n",
    " 'envato.com',\n",
    " 'ning.com',\n",
    " 'postgresql.org',\n",
    " 'urbandictionary.com',\n",
    " 'readthedocs.io',\n",
    " 'technologyreview.com',\n",
    " 'hackmd.io']:\n",
    "    df = get_dyn_results(site)\n",
    "    print(f\"Doing {site}, df.shape: {df.shape}\")\n",
    "    working_df, working_urls, url_dict = get_working_urls_channels(df, log=False)\n",
    "    display(working_urls)\n",
    "    display(working_df)\n",
    "    # pd.DataFrame.from_dict(json.loads(json.dumps(working_df.to_dict(\"list\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd7129e-26b8-4185-8ceb-876870cf3127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset counter, to be able to retest site\n",
    "import json\n",
    "#r.set(\"hackmd.io\", json.dumps([ {'domain': 'hackmd.io', 'name': 'sectionFilterApplied', 'value': 'true', 'path': '/', 'httpOnly': False, 'secure': False}, {'domain': 'hackmd.io', 'secure': True, 'value': 's%3A93EUlGSOqODk1Dm6cd4twh1NcRy5Fi4v.8KZtWWt67yLRN%2FCpXEzExoXJlY0sOxBcOTIfdWVPg%2BY', 'expiry': 1725511081, 'path': '/', 'httpOnly': True, 'name': 'connect.sid'},  {'domain': 'hackmd.io', 'secure': True, 'value': 'en-US', 'expiry': 1655837481, 'path': '/', 'httpOnly': False, 'name': 'locale'},  {'domain': 'hackmd.io', 'name': 'sectionsSortStrategy', 'value': 'cat_new_to_old', 'path': '/', 'httpOnly': False, 'secure': False}, {'domain': 'hackmd.io', 'name': 'overviewLayoutStrategy', 'value': '', 'path': '/', 'httpOnly': False, 'secure': False}, {'domain': 'hackmd.io', 'name': '_csrf', 'value': 'Vi1fP7b2S0iCMyxwHtmz6m5A', 'path': '/', 'httpOnly': False, 'secure': False}, {'domain': 'hackmd.io', 'name': 'notesSortStrategy', 'value': 'new_to_old', 'path': '/', 'httpOnly': False, 'secure': False}]))\n",
    "for site in [\"172.17.0.1:44320\", \"172.17.0.1:44320-unpruned\"]:\n",
    "    print(r.get(f\"{site}::first_count\"))\n",
    "    r.set(f\"{site}::first_count\", 0)\n",
    "    r.set(f\"{site}::second_count\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60296db1-e55d-4de5-bb5f-45cb55102f49",
   "metadata": {},
   "source": [
    "# OLD stuff below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701865d0-cc4e-4356-9e0b-779d777d6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import get_ef, get_gf, get_of, get_wf\n",
    "ef = get_ef()\n",
    "gf = get_gf()\n",
    "of = get_of()\n",
    "wf = get_wf()\n",
    "res = pot\n",
    "res = res.merge(ef, how=\"left\", on=\"events_id\")\n",
    "res = res.merge(gf, how=\"left\", on=\"global_properties_id\")\n",
    "res = res.merge(of, how=\"left\", on=\"object_properties_id\")\n",
    "res = res.merge(wf, how=\"left\", on=\"window_properties_id\")\n",
    "display(pot.sort_values([\"test_id\", \"browser_id\", \"cookies\"]))\n",
    "display(res.sort_values([\"test_id\", \"browser_id\", \"cookies\"])[[\"test_id\", \"browser_id\", \"cookies\", \"retest_num\", \"op_frame_count\", \"gp_window_postMessage\"]])\n",
    "res[\"event_set\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b1d87c-4dcb-43a0-b8c6-bc2d23bcc644",
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrid.show_grid(df.loc[df[\"test_id\"].isin(pot[\"test_id\"]) & (df[\"window_properties_id\"] != 109)].sort_values([\"test_id\", \"cookies\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7601b478-04fa-46a6-9f92-ad5de36bf465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "import os\n",
    "# save URLs dict to file (json?) and start the dynamic confirmation\n",
    "# Run the automator framework with correct db settings + dict input + higher timeouts\n",
    "# Start the framework twice? once with cookies and once without cookies?!\n",
    "# Add cookies column to db/what about test? (maybe better to just put it into another table in the db!)\n",
    "# (XSSI handling needs to be added)\n",
    "url_dict_path =  f\"data/{site}.json\"\n",
    "with open(url_dict_path, \"w\") as f:\n",
    "    json.dump(urls, f)\n",
    "print(site)\n",
    "os.environ[\"PIPENV_DOTENV_LOCATION\"] = \"../.env\"\n",
    "#print(subprocess.check_output([\"pipenv\", \"run\", \"python\", \"test_browsers.py\", \"local_grid\", f\"../analysis/{url_dict_path}\", site, \"True\", \"Test\"], cwd=\"../automator\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf002808-4adb-4f6b-9264-1765d044b5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "at = af.reset_index(drop=True)\n",
    "display(at)\n",
    "start = time.time()\n",
    "for file in glob.glob(\"trees/tenmin/mojo/[1,2]/*.mojo\"):\n",
    "    break\n",
    "    if \"conflicted\" in file:\n",
    "        continue\n",
    "    print(file)\n",
    "    res = h2o.mojo_predict_pandas(at[th_headers], file, genmodel_jar_path=\"/home/jannis/Downloads/h2o-3.32.1.1/h2o.jar\")\n",
    "    if res[\"predict\"].nunique() > 1:\n",
    "        res = pd.concat([at, res], axis=1)\n",
    "        valid = res.groupby(\"URL\")[\"predict\"].nunique()\n",
    "        valid = valid[valid > 1]\n",
    "        leaky = res.loc[res[\"URL\"].isin(valid.index)]\n",
    "        display(leaky)\n",
    "print(f\"Took {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3a8166-a152-45d7-8680-1a4d922b621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_path = \"/home/jannis/Downloads/h2o-3.32.1.1/h2o.jar\"\n",
    "dat = af.groupby(\"URL\")\n",
    "# Replace by only good working ones?, otherwise we have too many trees!\n",
    "files = glob.glob(\"trees/mojo/[1,2]/*.mojo\")\n",
    "files = [file for file in files if not \"conflicted\" in file]\n",
    "print(len(files))\n",
    "for key, item in dat:\n",
    "    continue\n",
    "    df = dat.get_group(key)\n",
    "    both = df[th_headers]\n",
    "    working = []\n",
    "    for file in files:\n",
    "        # Remove the (errornous) output of h2o: change file at path: /..../site-packages/h2o/utils/shared_utils.py line 414: to_csv add index=False\n",
    "        res = h2o.mojo_predict_pandas(both, file, genmodel_jar_path=gen_path)\n",
    "        if res[\"predict\"].nunique() == 2:\n",
    "            working.append(file)\n",
    "    print(working)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
